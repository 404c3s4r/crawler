# Globo Scraping

#### Este √© um projeto simples de web scraping desenvolvido em Python para extrair links da globo.com. Ele utiliza as bibliotecas requests e BeautifulSoup para coletar informa√ß√µes das p√°ginas web e permite a coleta e filtragem de par√¢metros.


### O objetivo 
Principal deste projeto √© fornecer uma ferramenta de scraping para coletar links de maneira automatizada e filtrar par√¢metros de URLs. Este c√≥digo pode ser usado como base para projetos mais avan√ßados ou para entender os conceitos b√°sicos de scraping e seguran√ßa web.



## Como usar ?

Instala√ß√£o das Depend√™ncias:
```bash
  pip3 install -r requirements.txt
```
Para utilizar este projeto, siga os passos abaixo:

### Execu√ß√£o do Scraping

Ap√≥s a instala√ß√£o das depend√™ncias, voc√™ pode executar o arquivo craw.py para iniciar o scraping dos links da p√°gina alvo.

Crawling de urls:
```bash
  python3 craw.py https://www.globo.com/ --urls 
```
Filtragem de URL:
![image](https://github.com/user-attachments/assets/3be792a5-1010-4898-931a-98c4a893f32e)

Crawling de emails:
```bash
  python3 craw.py https://www.globo.com/ --emais
```
Filtragem de Emails: 
![image](https://github.com/user-attachments/assets/7e718377-c200-4caa-91fd-35e2c62cfa60)





O c√≥digo ir√° coletar os links da p√°gina alvo e exibir os par√¢metros coletados no console. 


A estrutura de pastas do projeto est√° organizada da seguinte maneira:


```bash
Globo_Scraping/
‚îÇ
‚îú‚îÄ‚îÄ ‚îÄ‚îÄ crawling/
‚îÇ   ‚îú‚îÄ‚îÄ craw.py # Arquivo principal onde voc√™ inicia o web scraping
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt  # Arquivo que lista todas as depend√™ncias do projeto
‚îî   ‚îú‚îÄ‚îÄ README.md         

```

## Technology Used:
- **Python** 
   
## üîó Links
[![linkedin](https://img.shields.io/badge/linkedin-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/robertocoliver/)
[![portfolio](https://img.shields.io/badge/my_portfolio-000?style=for-the-badge&logo=ko-fi&logoColor=white)](https://medium.com/@robertocoliver)


Avisos Importantes
> Uso Respons√°vel: Este projeto foi desenvolvido para fins educacionais e de aprendizado. Sempre respeite os termos de servi√ßo dos sites ao realizar web scraping.
> Limita√ß√µes e Restri√ß√µes: O scraping de sites pode ser contra os termos de servi√ßo de alguns sites. Verifique as pol√≠ticas de uso e os limites de solicita√ß√£o do site alvo antes de executar o c√≥digo.

